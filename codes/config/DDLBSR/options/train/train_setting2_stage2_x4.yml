#### general settings
name: 001_D2SR_setting2_stage2_x4_c1_s0
use_tb_logger: true
model: stage2
distortion: sr
scale: 4
gpu_ids: [3]
cal_ker: True
ksize: 31

# train
degradation:
  random_kernel: true
  ksize: 31
  code_length: 10
  sig_min: 0.6
  sig_max: 5
  rate_iso: 0
  random_disturb: true
pca_matrix_path: /userHome/guest/wangjia/blindsr/D2SR/pca_matrix/pca_aniso_matrix_x2.pth



#### datasets
datasets:
  train:
    name: DIV2K+Flickr2K
    mode: GT
    dataroot_GT: /data/wangjia/BSR/train/DF2K/HR
    dataroot_LQ: ~

    use_shuffle: true
    n_workers: 8
    batch_size: 10
    GT_size: 256
    LR_size: 64
    use_flip: true
    use_rot: true
    color: RGB
  val:
    name: Set5
    mode: LQGT
    dataroot_GT: /data/wangjia/BSR/test/Setting2/Set5/HR/x4
    dataroot_LQ: /data/wangjia/BSR/test/Setting2/Set5/LRblur/x4

#### network structures
network_G:
  which_model_G: D2SR_s2
  setting:
    scale: 4
    ksize: 31


#### path
path:
  pretrain_model_G: /userHome/guest/wangjia/blindsr/D2SR/experiments/pretrained_models/295000_G.pth
  pretrain_model: ~
  #  /home/wangjia/code/blind-sr/D2SR/experiments/pretrained_models/D2SR_stage2_80000_G.pth
  strict_load: false
  resume_state: ~ #../experiments/001_MANet_aniso_x4_DIV2K_40_stage2/training_state/5000.state


#### training settings: learning rate scheme, loss
train:
  lr_E: !!float 2e-4
  lr_scheme: MultiStepLR
  beta1: 0.9
  beta2: 0.999
  niter: 3000000
  warmup_iter: -1
  lr_steps: [100000, 150000, 200000, 250000]
  lr_gamma: 0.5
  restarts: ~
  restart_weights: ~
  eta_min: !!float 1e-7

  kernel_criterion: l1
  kernel_weight: 1.0

  nl_weight: 0 # softmax loss weight
  c_weight: 1

  manual_seed: 0
  val_freq: !!float 5e3


#### logger
logger:
  print_freq: 200
  save_checkpoint_freq: !!float 5e3
